lockVersion: 2.0.0
id: f3669dca-8853-4d85-914e-fb38172139b6
management:
  docChecksum: 00f3762aadb2975f250ad4cba4a8eb41
  docVersion: 0.1.0
  speakeasyVersion: 1.517.3
  generationVersion: 2.548.6
  releaseVersion: 0.7.3
  configChecksum: 2dd5527b2f55f35fbad452c6a8062e24
  repoURL: https://github.com/friendliai/friendli-python.git
  installationURL: https://github.com/friendliai/friendli-python.git
  published: true
features:
  python:
    additionalDependencies: 1.0.0
    constsAndDefaults: 1.0.5
    core: 5.12.3
    defaultEnabledRetries: 0.2.0
    enumUnions: 0.1.0
    envVarSecurityUsage: 0.3.2
    examples: 3.0.1
    flatRequests: 1.0.1
    flattening: 3.1.1
    globalSecurity: 3.0.3
    globalSecurityCallbacks: 1.0.0
    globalSecurityFlattening: 1.0.0
    globalServerURLs: 3.1.0
    methodArguments: 1.0.2
    methodServerURLs: 3.1.1
    nameOverrides: 3.0.1
    nullables: 1.0.1
    responseFormat: 1.0.1
    retries: 3.0.2
    sdkHooks: 1.0.1
    serverEvents: 1.0.7
    serverEventsSentinels: 0.1.0
    unions: 3.0.4
generatedFiles:
  - .gitattributes
  - .python-version
  - .vscode/settings.json
  - USAGE.md
  - docs/models/acceleratorrequirement.md
  - docs/models/assistantmessage.md
  - docs/models/assistantmessagetoolcall.md
  - docs/models/assistantmessagetoolcallfunction.md
  - docs/models/audiocontent.md
  - docs/models/audiodata.md
  - docs/models/autoscalingpolicy.md
  - docs/models/b64imageitem.md
  - docs/models/b64imageitemformat.md
  - docs/models/chatchoice.md
  - docs/models/chatchoicemessage.md
  - docs/models/chatcompletebodytoolchoice.md
  - docs/models/chatcompletebodytoolchoicefunction.md
  - docs/models/chatlogprobs.md
  - docs/models/chatlogprobscontent.md
  - docs/models/chatlogprobscontenttoplogprob.md
  - docs/models/chatusage.md
  - docs/models/completionsbodywithprompt.md
  - docs/models/completionsbodywithpromptprompt.md
  - docs/models/completionsbodywithpromptseed.md
  - docs/models/completionsbodywithtokens.md
  - docs/models/completionsbodywithtokensseed.md
  - docs/models/completionschoice.md
  - docs/models/completionschoicefinishreason.md
  - docs/models/completionsdedicatedmodelbodywithprompt.md
  - docs/models/completionsdedicatedmodelbodywithpromptprompt.md
  - docs/models/completionsdedicatedmodelbodywithpromptseed.md
  - docs/models/completionsdedicatedmodelbodywithtokens.md
  - docs/models/completionsdedicatedmodelbodywithtokensseed.md
  - docs/models/completionslogprobs.md
  - docs/models/completionsserverlessmodelbodywithprompt.md
  - docs/models/completionsserverlessmodelbodywithpromptseed.md
  - docs/models/completionsserverlessmodelbodywithtokens.md
  - docs/models/completionsserverlessmodelbodywithtokensseed.md
  - docs/models/completionsstreambodywithprompt.md
  - docs/models/completionsstreambodywithpromptprompt.md
  - docs/models/completionsstreambodywithpromptseed.md
  - docs/models/completionsstreambodywithtokens.md
  - docs/models/completionsstreambodywithtokensseed.md
  - docs/models/completionsstreamdedicatedmodelbodywithprompt.md
  - docs/models/completionsstreamdedicatedmodelbodywithpromptprompt.md
  - docs/models/completionsstreamdedicatedmodelbodywithpromptseed.md
  - docs/models/completionsstreamdedicatedmodelbodywithtokens.md
  - docs/models/completionsstreamdedicatedmodelbodywithtokensseed.md
  - docs/models/completionsstreamserverlessmodelbodywithprompt.md
  - docs/models/completionsstreamserverlessmodelbodywithpromptprompt.md
  - docs/models/completionsstreamserverlessmodelbodywithpromptseed.md
  - docs/models/completionsstreamserverlessmodelbodywithtokens.md
  - docs/models/completionsstreamserverlessmodelbodywithtokensseed.md
  - docs/models/containerchatcompletesuccess.md
  - docs/models/containerchatcompletionbody.md
  - docs/models/containerchatcompletionbodylogitbias.md
  - docs/models/containerchatcompletionbodyseed.md
  - docs/models/containerchatcompletionbodytoolchoice.md
  - docs/models/containerchatcompletionstreambody.md
  - docs/models/containerchatcompletionstreambodylogitbias.md
  - docs/models/containerchatcompletionstreambodyseed.md
  - docs/models/containerchatcompletionstreambodytoolchoice.md
  - docs/models/containerchatcompletionstreamsuccess.md
  - docs/models/containercompletionsbody.md
  - docs/models/containercompletionsstreambody.md
  - docs/models/containercompletionsstreamsuccess.md
  - docs/models/containercompletionssuccess.md
  - docs/models/containerdetokenizationbody.md
  - docs/models/containerdetokenizationsuccess.md
  - docs/models/containertokenizationbody.md
  - docs/models/containertokenizationsuccess.md
  - docs/models/content.md
  - docs/models/data.md
  - docs/models/dedicatedchatcompleterequest.md
  - docs/models/dedicatedchatcompletesuccess.md
  - docs/models/dedicatedchatcompletionbody.md
  - docs/models/dedicatedchatcompletionbodylogitbias.md
  - docs/models/dedicatedchatcompletionbodyseed.md
  - docs/models/dedicatedchatcompletionbodytoolchoice.md
  - docs/models/dedicatedchatcompletionstreambody.md
  - docs/models/dedicatedchatcompletionstreambodylogitbias.md
  - docs/models/dedicatedchatcompletionstreambodyseed.md
  - docs/models/dedicatedchatcompletionstreambodytoolchoice.md
  - docs/models/dedicatedchatcompletionstreamsuccess.md
  - docs/models/dedicatedchatstreamrequest.md
  - docs/models/dedicatedcompletionsbody.md
  - docs/models/dedicatedcompletionscompleterequest.md
  - docs/models/dedicatedcompletionsstreambody.md
  - docs/models/dedicatedcompletionsstreamrequest.md
  - docs/models/dedicatedcompletionsstreamsuccess.md
  - docs/models/dedicatedcompletionssuccess.md
  - docs/models/dedicateddetokenizationbody.md
  - docs/models/dedicateddetokenizationrequest.md
  - docs/models/dedicateddetokenizationsuccess.md
  - docs/models/dedicatedendpointwandbartifactcreatebody.md
  - docs/models/dedicatedendpointwandbartifactcreaterequest.md
  - docs/models/dedicatedendpointwandbartifactcreateresponse.md
  - docs/models/dedicatedimagegeneratesuccess.md
  - docs/models/dedicatedimagegenerationbody.md
  - docs/models/dedicatedimagegenerationbodyresponseformat.md
  - docs/models/dedicatedimagesgeneraterequest.md
  - docs/models/dedicatedtokenizationbody.md
  - docs/models/dedicatedtokenizationrequest.md
  - docs/models/dedicatedtokenizationsuccess.md
  - docs/models/filebuiltintool.md
  - docs/models/finishreason.md
  - docs/models/format_.md
  - docs/models/function.md
  - docs/models/functionality.md
  - docs/models/functionresult.md
  - docs/models/imagecontent.md
  - docs/models/imagedata.md
  - docs/models/knowledgeretrievedchunk.md
  - docs/models/logitbias.md
  - docs/models/message.md
  - docs/models/modelcatalogresponseitem.md
  - docs/models/name.md
  - docs/models/otherbuiltintool.md
  - docs/models/parameters.md
  - docs/models/pricingmodel.md
  - docs/models/prompt.md
  - docs/models/responseformat.md
  - docs/models/responseformatjsonobject.md
  - docs/models/responseformatjsonschema.md
  - docs/models/responseformatjsonschemaschema.md
  - docs/models/responseformatregex.md
  - docs/models/responseformattext.md
  - docs/models/schema.md
  - docs/models/security.md
  - docs/models/seed.md
  - docs/models/serverlesschatcompleterequest.md
  - docs/models/serverlesschatcompletesuccess.md
  - docs/models/serverlesschatcompletionbody.md
  - docs/models/serverlesschatcompletionstreambody.md
  - docs/models/serverlesschatcompletionstreambodylogitbias.md
  - docs/models/serverlesschatcompletionstreambodyseed.md
  - docs/models/serverlesschatcompletionstreambodytoolchoice.md
  - docs/models/serverlesschatcompletionstreamsuccess.md
  - docs/models/serverlesschatstreamrequest.md
  - docs/models/serverlesscompletionsbody.md
  - docs/models/serverlesscompletionscompleterequest.md
  - docs/models/serverlesscompletionsstreambody.md
  - docs/models/serverlesscompletionsstreamrequest.md
  - docs/models/serverlesscompletionsstreamsuccess.md
  - docs/models/serverlesscompletionssuccess.md
  - docs/models/serverlessdetokenizationbody.md
  - docs/models/serverlessdetokenizationrequest.md
  - docs/models/serverlessdetokenizationsuccess.md
  - docs/models/serverlessknowledgeretrievalbody.md
  - docs/models/serverlessknowledgeretrievalsuccess.md
  - docs/models/serverlessknowledgeretrieverequest.md
  - docs/models/serverlessmodellistsuccess.md
  - docs/models/serverlesstokenizationbody.md
  - docs/models/serverlesstokenizationrequest.md
  - docs/models/serverlesstokenizationsuccess.md
  - docs/models/serverlesstoolassistedchatcompleterequest.md
  - docs/models/serverlesstoolassistedchatcompletesuccess.md
  - docs/models/serverlesstoolassistedchatcompletionbody.md
  - docs/models/serverlesstoolassistedchatcompletionbodylogitbias.md
  - docs/models/serverlesstoolassistedchatcompletionbodyseed.md
  - docs/models/serverlesstoolassistedchatcompletionbodytoolchoice.md
  - docs/models/serverlesstoolassistedchatcompletionstreambody.md
  - docs/models/serverlesstoolassistedchatcompletionstreambodylogitbias.md
  - docs/models/serverlesstoolassistedchatcompletionstreambodyseed.md
  - docs/models/serverlesstoolassistedchatcompletionstreambodytoolchoice.md
  - docs/models/serverlesstoolassistedchatcompletionstreamsuccess.md
  - docs/models/serverlesstoolassistedchatstreamrequest.md
  - docs/models/status.md
  - docs/models/streamedchatchoice.md
  - docs/models/streamedchatchoicedelta.md
  - docs/models/streamedchatchoicefinishreason.md
  - docs/models/streamedchatdata.md
  - docs/models/streamedcompletiondata.md
  - docs/models/streamedcompletionschoice.md
  - docs/models/streamedcompletionschoicefinishreason.md
  - docs/models/streamedfunctionresult.md
  - docs/models/streamedtoolassistedchattoken.md
  - docs/models/streamedtoolassistedchattoolstatus.md
  - docs/models/streamedtoolcallresult.md
  - docs/models/streamoptions.md
  - docs/models/systemmessage.md
  - docs/models/textcontent.md
  - docs/models/tokensequence.md
  - docs/models/tool.md
  - docs/models/toolassistedchattool.md
  - docs/models/toolcallresult.md
  - docs/models/toolchoice.md
  - docs/models/toolmessage.md
  - docs/models/toolstatusdata.md
  - docs/models/toolstatuserror.md
  - docs/models/toolstatusfile.md
  - docs/models/toolstatusparameter.md
  - docs/models/toplogprobs.md
  - docs/models/type.md
  - docs/models/urlimageitem.md
  - docs/models/usage.md
  - docs/models/usermessage.md
  - docs/models/usermessagecontentmultimodal.md
  - docs/models/utils/retryconfig.md
  - docs/models/videocontent.md
  - docs/models/videodata.md
  - docs/sdks/chat/README.md
  - docs/sdks/completions/README.md
  - docs/sdks/container/README.md
  - docs/sdks/dedicated/README.md
  - docs/sdks/endpoint/README.md
  - docs/sdks/friendli/README.md
  - docs/sdks/friendlichat/README.md
  - docs/sdks/friendlicompletions/README.md
  - docs/sdks/friendlicontainerchat/README.md
  - docs/sdks/friendlicontainercompletions/README.md
  - docs/sdks/friendlicontainertoken/README.md
  - docs/sdks/friendlitoken/README.md
  - docs/sdks/image/README.md
  - docs/sdks/knowledge/README.md
  - docs/sdks/model/README.md
  - docs/sdks/serverless/README.md
  - docs/sdks/token/README.md
  - docs/sdks/toolassistedchat/README.md
  - poetry.toml
  - py.typed
  - pylintrc
  - pyproject.toml
  - scripts/publish.sh
  - src/friendli/__init__.py
  - src/friendli/_hooks/__init__.py
  - src/friendli/_hooks/sdkhooks.py
  - src/friendli/_hooks/types.py
  - src/friendli/_version.py
  - src/friendli/basesdk.py
  - src/friendli/chat.py
  - src/friendli/completions.py
  - src/friendli/container.py
  - src/friendli/dedicated.py
  - src/friendli/endpoint.py
  - src/friendli/friendli_chat.py
  - src/friendli/friendli_completions.py
  - src/friendli/friendli_container_chat.py
  - src/friendli/friendli_container_completions.py
  - src/friendli/friendli_container_token.py
  - src/friendli/friendli_token.py
  - src/friendli/httpclient.py
  - src/friendli/image.py
  - src/friendli/knowledge.py
  - src/friendli/model.py
  - src/friendli/models/__init__.py
  - src/friendli/models/acceleratorrequirement.py
  - src/friendli/models/assistantmessage.py
  - src/friendli/models/assistantmessagetoolcall.py
  - src/friendli/models/assistantmessagetoolcallfunction.py
  - src/friendli/models/audiocontent.py
  - src/friendli/models/audiodata.py
  - src/friendli/models/autoscalingpolicy.py
  - src/friendli/models/b64imageitem.py
  - src/friendli/models/chatchoice.py
  - src/friendli/models/chatchoicemessage.py
  - src/friendli/models/chatcompletebodytoolchoice.py
  - src/friendli/models/chatcompletebodytoolchoicefunction.py
  - src/friendli/models/chatlogprobs.py
  - src/friendli/models/chatlogprobscontent.py
  - src/friendli/models/chatlogprobscontenttoplogprob.py
  - src/friendli/models/chatusage.py
  - src/friendli/models/completionsbodywithprompt.py
  - src/friendli/models/completionsbodywithtokens.py
  - src/friendli/models/completionschoice.py
  - src/friendli/models/completionsdedicatedmodelbodywithprompt.py
  - src/friendli/models/completionsdedicatedmodelbodywithtokens.py
  - src/friendli/models/completionslogprobs.py
  - src/friendli/models/completionsserverlessmodelbodywithprompt.py
  - src/friendli/models/completionsserverlessmodelbodywithtokens.py
  - src/friendli/models/completionsstreambodywithprompt.py
  - src/friendli/models/completionsstreambodywithtokens.py
  - src/friendli/models/completionsstreamdedicatedmodelbodywithprompt.py
  - src/friendli/models/completionsstreamdedicatedmodelbodywithtokens.py
  - src/friendli/models/completionsstreamserverlessmodelbodywithprompt.py
  - src/friendli/models/completionsstreamserverlessmodelbodywithtokens.py
  - src/friendli/models/containerchatcompleteop.py
  - src/friendli/models/containerchatcompletesuccess.py
  - src/friendli/models/containerchatcompletionbody.py
  - src/friendli/models/containerchatcompletionstreambody.py
  - src/friendli/models/containerchatcompletionstreamsuccess.py
  - src/friendli/models/containerchatstreamop.py
  - src/friendli/models/containercompletionsbody.py
  - src/friendli/models/containercompletionscompleteop.py
  - src/friendli/models/containercompletionsstreambody.py
  - src/friendli/models/containercompletionsstreamop.py
  - src/friendli/models/containercompletionsstreamsuccess.py
  - src/friendli/models/containercompletionssuccess.py
  - src/friendli/models/containerdetokenizationbody.py
  - src/friendli/models/containerdetokenizationop.py
  - src/friendli/models/containerdetokenizationsuccess.py
  - src/friendli/models/containertokenizationbody.py
  - src/friendli/models/containertokenizationop.py
  - src/friendli/models/containertokenizationsuccess.py
  - src/friendli/models/dedicatedchatcompleteop.py
  - src/friendli/models/dedicatedchatcompletesuccess.py
  - src/friendli/models/dedicatedchatcompletionbody.py
  - src/friendli/models/dedicatedchatcompletionstreambody.py
  - src/friendli/models/dedicatedchatcompletionstreamsuccess.py
  - src/friendli/models/dedicatedchatstreamop.py
  - src/friendli/models/dedicatedcompletionsbody.py
  - src/friendli/models/dedicatedcompletionscompleteop.py
  - src/friendli/models/dedicatedcompletionsstreambody.py
  - src/friendli/models/dedicatedcompletionsstreamop.py
  - src/friendli/models/dedicatedcompletionsstreamsuccess.py
  - src/friendli/models/dedicatedcompletionssuccess.py
  - src/friendli/models/dedicateddetokenizationbody.py
  - src/friendli/models/dedicateddetokenizationop.py
  - src/friendli/models/dedicateddetokenizationsuccess.py
  - src/friendli/models/dedicatedendpointwandbartifactcreatebody.py
  - src/friendli/models/dedicatedendpointwandbartifactcreateop.py
  - src/friendli/models/dedicatedendpointwandbartifactcreateresponse.py
  - src/friendli/models/dedicatedimagegeneratesuccess.py
  - src/friendli/models/dedicatedimagegenerationbody.py
  - src/friendli/models/dedicatedimagesgenerateop.py
  - src/friendli/models/dedicatedtokenizationbody.py
  - src/friendli/models/dedicatedtokenizationop.py
  - src/friendli/models/dedicatedtokenizationsuccess.py
  - src/friendli/models/filebuiltintool.py
  - src/friendli/models/function.py
  - src/friendli/models/functionality.py
  - src/friendli/models/functionresult.py
  - src/friendli/models/imagecontent.py
  - src/friendli/models/imagedata.py
  - src/friendli/models/knowledgeretrievedchunk.py
  - src/friendli/models/message.py
  - src/friendli/models/modelcatalogresponseitem.py
  - src/friendli/models/otherbuiltintool.py
  - src/friendli/models/pricingmodel.py
  - src/friendli/models/responseformat.py
  - src/friendli/models/responseformatjsonobject.py
  - src/friendli/models/responseformatjsonschema.py
  - src/friendli/models/responseformatjsonschemaschema.py
  - src/friendli/models/responseformatregex.py
  - src/friendli/models/responseformattext.py
  - src/friendli/models/sdkerror.py
  - src/friendli/models/security.py
  - src/friendli/models/serverlesschatcompleteop.py
  - src/friendli/models/serverlesschatcompletesuccess.py
  - src/friendli/models/serverlesschatcompletionbody.py
  - src/friendli/models/serverlesschatcompletionstreambody.py
  - src/friendli/models/serverlesschatcompletionstreamsuccess.py
  - src/friendli/models/serverlesschatstreamop.py
  - src/friendli/models/serverlesscompletionsbody.py
  - src/friendli/models/serverlesscompletionscompleteop.py
  - src/friendli/models/serverlesscompletionsstreambody.py
  - src/friendli/models/serverlesscompletionsstreamop.py
  - src/friendli/models/serverlesscompletionsstreamsuccess.py
  - src/friendli/models/serverlesscompletionssuccess.py
  - src/friendli/models/serverlessdetokenizationbody.py
  - src/friendli/models/serverlessdetokenizationop.py
  - src/friendli/models/serverlessdetokenizationsuccess.py
  - src/friendli/models/serverlessknowledgeretrievalbody.py
  - src/friendli/models/serverlessknowledgeretrievalsuccess.py
  - src/friendli/models/serverlessknowledgeretrieveop.py
  - src/friendli/models/serverlessmodellistsuccess.py
  - src/friendli/models/serverlesstokenizationbody.py
  - src/friendli/models/serverlesstokenizationop.py
  - src/friendli/models/serverlesstokenizationsuccess.py
  - src/friendli/models/serverlesstoolassistedchatcompleteop.py
  - src/friendli/models/serverlesstoolassistedchatcompletesuccess.py
  - src/friendli/models/serverlesstoolassistedchatcompletionbody.py
  - src/friendli/models/serverlesstoolassistedchatcompletionstreambody.py
  - src/friendli/models/serverlesstoolassistedchatcompletionstreamsuccess.py
  - src/friendli/models/serverlesstoolassistedchatstreamop.py
  - src/friendli/models/streamedchatchoice.py
  - src/friendli/models/streamedchatchoicedelta.py
  - src/friendli/models/streamedchatdata.py
  - src/friendli/models/streamedcompletiondata.py
  - src/friendli/models/streamedcompletionschoice.py
  - src/friendli/models/streamedfunctionresult.py
  - src/friendli/models/streamedtoolassistedchattoken.py
  - src/friendli/models/streamedtoolassistedchattoolstatus.py
  - src/friendli/models/streamedtoolcallresult.py
  - src/friendli/models/streamoptions.py
  - src/friendli/models/systemmessage.py
  - src/friendli/models/textcontent.py
  - src/friendli/models/tokensequence.py
  - src/friendli/models/tool.py
  - src/friendli/models/toolassistedchattool.py
  - src/friendli/models/toolcallresult.py
  - src/friendli/models/toolmessage.py
  - src/friendli/models/toolstatusdata.py
  - src/friendli/models/toolstatuserror.py
  - src/friendli/models/toolstatusfile.py
  - src/friendli/models/toolstatusparameter.py
  - src/friendli/models/urlimageitem.py
  - src/friendli/models/usage.py
  - src/friendli/models/usermessage.py
  - src/friendli/models/usermessagecontentmultimodal.py
  - src/friendli/models/videocontent.py
  - src/friendli/models/videodata.py
  - src/friendli/py.typed
  - src/friendli/sdk.py
  - src/friendli/sdkconfiguration.py
  - src/friendli/serverless.py
  - src/friendli/token.py
  - src/friendli/toolassistedchat.py
  - src/friendli/types/__init__.py
  - src/friendli/types/basemodel.py
  - src/friendli/utils/__init__.py
  - src/friendli/utils/enums.py
  - src/friendli/utils/eventstreaming.py
  - src/friendli/utils/forms.py
  - src/friendli/utils/headers.py
  - src/friendli/utils/logger.py
  - src/friendli/utils/metadata.py
  - src/friendli/utils/queryparams.py
  - src/friendli/utils/requestbodies.py
  - src/friendli/utils/retries.py
  - src/friendli/utils/security.py
  - src/friendli/utils/serializers.py
  - src/friendli/utils/url.py
  - src/friendli/utils/values.py
examples:
  serverlessChatComplete:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "You are a helpful assistant.", "role": "system"}, {"content": "Hello!", "role": "user"}], "model": "meta-llama-3.1-8b-instruct", "stream": false}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "message": {"role": "assistant", "content": "Hello there, how may I assist you today?"}}], "created": 1735722153, "id": "chatcmpl-4b71d12c86d94e719c7e3984a7bb7941", "object": "chat.completion", "usage": {"completion_tokens": 11, "prompt_tokens": 9, "total_tokens": 20}, "model": "meta-llama-3.1-8b-instruct"}
  serverlessChatStream:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "You are a helpful assistant.", "role": "system"}, {"content": "Hello!", "role": "user"}], "model": "meta-llama-3.1-8b-instruct", "stream": true}
      responses:
        "200":
          text/event-stream: "data: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"This\"},\"finish_reason\":null,\"logprobs\":null}],\"usage\":null,\"created\":1726294381}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"finish_reason\":null,\"logprobs\":null}],\"usage\":null,\"created\":1726294381}\n\n...\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{},\"finish_reason\":\"stop\",\"logprobs\":null}],\"usage\":null,\"created\":1726294383}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[],\"usage\":{\"prompt_tokens\":8,\"completion_tokens\":4,\"total_tokens\":12},\"created\":1726294402}\n\ndata: [DONE]\n"
  serverlessCompletionsComplete:
    Example:
      requestBody:
        application/json: {"model": "meta-llama-3.1-8b-instruct", "prompt": "Say this is a test!", "stream": false}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "seed": 42, "text": "This is indeed a test", "tokens": [128000, 2028, 374, 13118, 264, 1296]}], "id": "cmpl-26a1e10db8544bc3adb488d2d205288b", "object": "text_completion", "usage": {"completion_tokens": 6, "prompt_tokens": 7, "total_tokens": 13}, "model": "meta-llama-3.1-8b-instruct"}
  serverlessCompletionsStream:
    Example:
      requestBody:
        application/json: {"model": "meta-llama-3.1-8b-instruct", "prompt": "Say this is a test!", "stream": true}
      responses:
        "200":
          text/event-stream: "data: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\" such\",\"token\":1778,\"finish_reason\":null,\"logprobs\":null}],\"created\":1733382157}\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\" as\",\"token\":439,\"finish_reason\":null,\"logprobs\":null}],\"created\":1733382157}\n\n...\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\"\",\"finish_reason\":\"length\",\"logprobs\":null}],\"created\":1733382157}\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[],\"usage\":{\"prompt_tokens\":5,\"completion_tokens\":10,\"total_tokens\":15},\"created\":1733382157}\n\ndata: [DONE]\n"
  serverlessTokenization:
    Example:
      requestBody:
        application/json: {"model": "meta-llama-3.1-8b-instruct", "prompt": "What is generative AI?"}
      responses:
        "200":
          application/json: {"tokens": [128000, 3923, 374, 1803, 1413, 15592, 30]}
  serverlessDetokenization:
    Example:
      requestBody:
        application/json: {"model": "meta-llama-3.1-8b-instruct", "tokens": [128000, 3923, 374, 1803, 1413, 15592, 30]}
      responses:
        "200":
          application/json: {"text": "What is generative AI?"}
  serverlessToolAssistedChatComplete:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "What is 3 + 6?", "role": "user"}], "model": "meta-llama-3.1-8b-instruct", "stream": false, "tools": [{"type": "math:calculator"}]}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "message": {"role": "assistant", "content": "The result is 9."}}], "created": 1735722153, "id": "chatcmpl-4b71d12c86d94e719c7e3984a7bb7941", "object": "chat.completion", "usage": {"completion_tokens": 11, "prompt_tokens": 9, "total_tokens": 20}, "model": "meta-llama-3.1-8b-instruct"}
  serverlessToolAssistedChatStream:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "What is 3 + 6?", "role": "user"}], "model": "meta-llama-3.1-8b-instruct", "stream": true, "tools": [{"type": "math:calculator"}]}
      responses:
        "200":
          text/event-stream: "event: tool_status\ndata: {\"tool_call_id\":\"call_3QrfStXSU6fGdOGPcETocIAq\",\"name\":\"math:calculator\",\"status\":\"STARTED\",\"parameters\":[{\"name\":\"expression\",\"value\":\"150 * 1.60934\"}],\"result\":null,\"files\":null,\"message\":null,\"error\":null,\"usage\":null,\"timestamp\":1726277121}\n\nevent: tool_status\ndata: {\"tool_call_id\":\"call_3QrfStXSU6fGdOGPcETocIAq\",\"name\":\"math:calculator\",\"status\":\"ENDED\",\"parameters\":[{\"name\":\"expression\",\"value\":\"150 * 1.60934\"}],\"result\":\"\"{\\\"result\\\": \\\"150 * 1.60934=241.401000000000\\\"}\"\",\"files\":null,\"message\":null,\"error\":null,\"usage\":null,\"timestamp\":1726277121}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"To\"},\"finish_reason\":null,\"logprobs\":null}],\"created\":1726277121}\n\n...\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\".\"},\"finish_reason\":null,\"logprobs\":null}],\"created\":1726277121}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{},\"finish_reason\":\"stop\",\"logprobs\":null}],\"created\":1726277121}\n\ndata: [DONE]\n"
  serverlessKnowledgeRetrieve:
    speakeasy-default-serverless-knowledge-retrieve:
      requestBody:
        application/json: {"k": 1, "knowledgeIds": ["knowledge-base-id-1"], "query": "Chicken dinner"}
      responses:
        "200":
          application/json: {"results": [{"contentChunkId": "<id>", "contentId": "<id>", "score": 8594.49, "text": "<value>"}]}
  serverlessModelList:
    speakeasy-default-serverless-model-list:
      responses:
        "200":
          application/json: {"data": []}
  dedicatedChatComplete:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "You are a helpful assistant.", "role": "system"}, {"content": "Hello!", "role": "user"}], "model": "(endpoint-id)", "stream": false}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "message": {"role": "assistant", "content": "Hello there, how may I assist you today?"}}], "created": 1735722153, "id": "chatcmpl-4b71d12c86d94e719c7e3984a7bb7941", "object": "chat.completion", "usage": {"completion_tokens": 11, "prompt_tokens": 9, "total_tokens": 20}, "model": "(endpoint-id)"}
  dedicatedChatStream:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "You are a helpful assistant.", "role": "system"}, {"content": "Hello!", "role": "user"}], "model": "(endpoint-id)", "stream": true}
      responses:
        "200":
          text/event-stream: "data: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"This\"},\"finish_reason\":null,\"logprobs\":null}],\"usage\":null,\"created\":1726294381}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"finish_reason\":null,\"logprobs\":null}],\"usage\":null,\"created\":1726294381}\n\n...\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{},\"finish_reason\":\"stop\",\"logprobs\":null}],\"usage\":null,\"created\":1726294383}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[],\"usage\":{\"prompt_tokens\":8,\"completion_tokens\":4,\"total_tokens\":12},\"created\":1726294402}\n\ndata: [DONE]\n"
  dedicatedCompletionsComplete:
    Example:
      requestBody:
        application/json: {"model": "(endpoint-id)", "prompt": "Say this is a test!", "stream": false}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "seed": 42, "text": "This is indeed a test", "tokens": [128000, 2028, 374, 13118, 264, 1296]}], "id": "cmpl-26a1e10db8544bc3adb488d2d205288b", "object": "text_completion", "usage": {"completion_tokens": 6, "prompt_tokens": 7, "total_tokens": 13}, "model": "(endpoint-id)"}
  dedicatedCompletionsStream:
    Example:
      requestBody:
        application/json: {"model": "(endpoint-id)", "prompt": "Say this is a test!", "stream": true}
      responses:
        "200":
          text/event-stream: "data: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\" such\",\"token\":1778,\"finish_reason\":null,\"logprobs\":null}],\"created\":1733382157}\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\" as\",\"token\":439,\"finish_reason\":null,\"logprobs\":null}],\"created\":1733382157}\n\n...\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\"\",\"finish_reason\":\"length\",\"logprobs\":null}],\"created\":1733382157}\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[],\"usage\":{\"prompt_tokens\":5,\"completion_tokens\":10,\"total_tokens\":15},\"created\":1733382157}\n\ndata: [DONE]\n"
  dedicatedTokenization:
    Example:
      requestBody:
        application/json: {"model": "(endpoint-id)", "prompt": "What is generative AI?"}
      responses:
        "200":
          application/json: {"tokens": [128000, 3923, 374, 1803, 1413, 15592, 30]}
  dedicatedDetokenization:
    Example:
      requestBody:
        application/json: {"model": "(endpoint-id)", "tokens": [128000, 3923, 374, 1803, 1413, 15592, 30]}
      responses:
        "200":
          application/json: {"text": "What is generative AI?"}
  dedicatedEndpointWandbArtifactCreate:
    Example:
      requestBody:
        application/json: {"wandbArtifactVersionName": "org/registry/name:v0"}
      responses:
        "200":
          application/json: {"endpointId": "endpoint-id", "endpointName": "endpoint-name", "projectId": "project-id", "projectName": "project-name", "teamId": "team-id", "teamName": "team-name"}
  containerChatComplete:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "You are a helpful assistant.", "role": "system"}, {"content": "Hello!", "role": "user"}], "stream": false}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "message": {"role": "assistant", "content": "Hello there, how may I assist you today?"}}], "created": 1735722153, "id": "chatcmpl-4b71d12c86d94e719c7e3984a7bb7941", "object": "chat.completion", "usage": {"completion_tokens": 11, "prompt_tokens": 9, "total_tokens": 20}}
  containerChatStream:
    Example:
      requestBody:
        application/json: {"messages": [{"content": "You are a helpful assistant.", "role": "system"}, {"content": "Hello!", "role": "user"}], "stream": true}
      responses:
        "200":
          text/event-stream: "data: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"This\"},\"finish_reason\":null,\"logprobs\":null}],\"usage\":null,\"created\":1726294381}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"finish_reason\":null,\"logprobs\":null}],\"usage\":null,\"created\":1726294381}\n\n...\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[{\"index\":0,\"delta\":{},\"finish_reason\":\"stop\",\"logprobs\":null}],\"usage\":null,\"created\":1726294383}\n\ndata: {\"id\":\"chatcmpl-4b71d12c86d94e719c7e3984a7bb7941\",\"object\":\"chat.completion.chunk\",\"choices\":[],\"usage\":{\"prompt_tokens\":8,\"completion_tokens\":4,\"total_tokens\":12},\"created\":1726294402}\n\ndata: [DONE]\n"
  containerCompletionsComplete:
    Example:
      requestBody:
        application/json: {"prompt": "Say this is a test!", "stream": false}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "seed": 42, "text": "This is indeed a test", "tokens": [128000, 2028, 374, 13118, 264, 1296]}], "id": "cmpl-26a1e10db8544bc3adb488d2d205288b", "object": "text_completion", "usage": {"completion_tokens": 6, "prompt_tokens": 7, "total_tokens": 13}}
  containerCompletionsStream:
    Example:
      requestBody:
        application/json: {"prompt": "Say this is a test!", "stream": true}
      responses:
        "200":
          text/event-stream: "data: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\" such\",\"token\":1778,\"finish_reason\":null,\"logprobs\":null}],\"created\":1733382157}\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\" as\",\"token\":439,\"finish_reason\":null,\"logprobs\":null}],\"created\":1733382157}\n\n...\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[{\"index\":0,\"text\":\"\",\"finish_reason\":\"length\",\"logprobs\":null}],\"created\":1733382157}\n\ndata: {\"id\":\"cmpl-26a1e10db8544bc3adb488d2d205288b\",\"object\":\"text_completion\",\"choices\":[],\"usage\":{\"prompt_tokens\":5,\"completion_tokens\":10,\"total_tokens\":15},\"created\":1733382157}\n\ndata: [DONE]\n"
  containerTokenization:
    Example:
      requestBody:
        application/json: {"prompt": "What is generative AI?"}
      responses:
        "200":
          application/json: {"tokens": [128000, 3923, 374, 1803, 1413, 15592, 30]}
  containerDetokenization:
    Example:
      requestBody:
        application/json: {"tokens": [128000, 3923, 374, 1803, 1413, 15592, 30]}
      responses:
        "200":
          application/json: {"text": "What is generative AI?"}
  dedicatedImagesGenerate:
    Example:
      requestBody:
        application/json: {"model": "(endpoint-id)", "prompt": "An orange Lamborghini driving down a hill road at night with a beautiful ocean view in the background.", "num_inference_steps": 4, "response_format": "url"}
      responses:
        "200":
          application/json: {"data": [{"b64_json": "0x75e5323006", "format": "raw", "seed": 105213}]}
examplesVersion: 1.0.0
generatedTests: {}
